{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropout Regularization In Deep Neural Network\n",
    "This is a dataset that describes sonar chirp returns bouncing off different services. The 60 input variables are the strength of the returns at different angles. It is a binary classification problem that requires a model to differentiate rocks from metal cylinders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.0218</td>\n",
       "      <td>0.0175</td>\n",
       "      <td>0.0362</td>\n",
       "      <td>0.0696</td>\n",
       "      <td>0.0873</td>\n",
       "      <td>0.0616</td>\n",
       "      <td>0.1252</td>\n",
       "      <td>0.1302</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0289</td>\n",
       "      <td>0.0713</td>\n",
       "      <td>0.1075</td>\n",
       "      <td>0.1019</td>\n",
       "      <td>0.1606</td>\n",
       "      <td>0.2119</td>\n",
       "      <td>0.3061</td>\n",
       "      <td>0.2936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0133</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>0.0541</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.0505</td>\n",
       "      <td>0.1097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0420</td>\n",
       "      <td>0.0865</td>\n",
       "      <td>0.1182</td>\n",
       "      <td>0.0999</td>\n",
       "      <td>0.1976</td>\n",
       "      <td>0.2318</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0293</td>\n",
       "      <td>0.0644</td>\n",
       "      <td>0.0390</td>\n",
       "      <td>0.0173</td>\n",
       "      <td>0.0476</td>\n",
       "      <td>0.0816</td>\n",
       "      <td>0.0993</td>\n",
       "      <td>0.0315</td>\n",
       "      <td>0.0736</td>\n",
       "      <td>0.0860</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1       2       3       4       5       6       7       8   \\\n",
       "59   0.0125  0.0152  0.0218  0.0175  0.0362  0.0696  0.0873  0.0616  0.1252   \n",
       "158  0.0107  0.0453  0.0289  0.0713  0.1075  0.1019  0.1606  0.2119  0.3061   \n",
       "25   0.0201  0.0026  0.0138  0.0062  0.0133  0.0151  0.0541  0.0210  0.0505   \n",
       "163  0.0072  0.0027  0.0089  0.0061  0.0420  0.0865  0.1182  0.0999  0.1976   \n",
       "24   0.0293  0.0644  0.0390  0.0173  0.0476  0.0816  0.0993  0.0315  0.0736   \n",
       "\n",
       "         9   ...      51      52      53      54      55      56      57  \\\n",
       "59   0.1302  ...  0.0041  0.0074  0.0030  0.0050  0.0048  0.0017  0.0041   \n",
       "158  0.2936  ...  0.0164  0.0120  0.0113  0.0021  0.0097  0.0072  0.0060   \n",
       "25   0.1097  ...  0.0108  0.0070  0.0063  0.0030  0.0011  0.0007  0.0024   \n",
       "163  0.2318  ...  0.0078  0.0071  0.0081  0.0034  0.0064  0.0037  0.0036   \n",
       "24   0.0860  ...  0.0035  0.0052  0.0083  0.0078  0.0075  0.0105  0.0160   \n",
       "\n",
       "         58      59  60  \n",
       "59   0.0086  0.0058   R  \n",
       "158  0.0017  0.0036   M  \n",
       "25   0.0057  0.0044   R  \n",
       "163  0.0012  0.0037   M  \n",
       "24   0.0095  0.0011   R  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"sonar_dataset.csv\", header=None)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "     ..\n",
       "56    0\n",
       "57    0\n",
       "58    0\n",
       "59    0\n",
       "60    0\n",
       "Length: 61, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for nan values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M    111\n",
       "R     97\n",
       "Name: 60, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[60].value_counts() # label is not skewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    R\n",
       "1    R\n",
       "2    R\n",
       "3    R\n",
       "4    R\n",
       "Name: 60, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(60, axis=1)\n",
    "y = df[60]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     R\n",
       "126  0\n",
       "28   1\n",
       "38   1\n",
       "173  0\n",
       "154  0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.get_dummies(y, drop_first=True)\n",
    "y.sample(5) # R --> 1 and M --> 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R\n",
       "0    111\n",
       "1     97\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.0403</td>\n",
       "      <td>0.0317</td>\n",
       "      <td>0.0293</td>\n",
       "      <td>0.0820</td>\n",
       "      <td>0.1342</td>\n",
       "      <td>0.1161</td>\n",
       "      <td>0.0663</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.0506</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.0433</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>0.0449</td>\n",
       "      <td>0.0597</td>\n",
       "      <td>0.0355</td>\n",
       "      <td>0.0531</td>\n",
       "      <td>0.0343</td>\n",
       "      <td>0.1052</td>\n",
       "      <td>0.2120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.0196</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>0.0062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0.0163</td>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0386</td>\n",
       "      <td>0.0752</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.1487</td>\n",
       "      <td>0.1484</td>\n",
       "      <td>0.2442</td>\n",
       "      <td>0.2822</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0420</td>\n",
       "      <td>0.0446</td>\n",
       "      <td>0.0551</td>\n",
       "      <td>0.0597</td>\n",
       "      <td>0.1416</td>\n",
       "      <td>0.0956</td>\n",
       "      <td>0.0802</td>\n",
       "      <td>0.1618</td>\n",
       "      <td>0.2558</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0641</td>\n",
       "      <td>0.1732</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.2559</td>\n",
       "      <td>0.2947</td>\n",
       "      <td>0.4110</td>\n",
       "      <td>0.4983</td>\n",
       "      <td>0.5920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0153</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1       2       3       4       5       6       7       8   \\\n",
       "67   0.0368  0.0403  0.0317  0.0293  0.0820  0.1342  0.1161  0.0663  0.0155   \n",
       "14   0.0124  0.0433  0.0604  0.0449  0.0597  0.0355  0.0531  0.0343  0.1052   \n",
       "164  0.0163  0.0198  0.0202  0.0386  0.0752  0.1444  0.1487  0.1484  0.2442   \n",
       "179  0.0394  0.0420  0.0446  0.0551  0.0597  0.1416  0.0956  0.0802  0.1618   \n",
       "19   0.0126  0.0149  0.0641  0.1732  0.2565  0.2559  0.2947  0.4110  0.4983   \n",
       "\n",
       "         9   ...      50      51      52      53      54      55      56  \\\n",
       "67   0.0506  ...  0.0058  0.0091  0.0160  0.0160  0.0081  0.0070  0.0135   \n",
       "14   0.2120  ...  0.0078  0.0083  0.0057  0.0174  0.0188  0.0054  0.0114   \n",
       "164  0.2822  ...  0.0027  0.0077  0.0026  0.0031  0.0083  0.0020  0.0084   \n",
       "179  0.2558  ...  0.0118  0.0146  0.0040  0.0114  0.0032  0.0062  0.0101   \n",
       "19   0.5920  ...  0.0153  0.0092  0.0035  0.0098  0.0121  0.0006  0.0181   \n",
       "\n",
       "         57      58      59  \n",
       "67   0.0067  0.0078  0.0068  \n",
       "14   0.0196  0.0147  0.0062  \n",
       "164  0.0108  0.0083  0.0033  \n",
       "179  0.0068  0.0053  0.0087  \n",
       "19   0.0094  0.0116  0.0063  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model without Dropout Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20/20 [==============================] - 1s 2ms/step - loss: 0.6995 - accuracy: 0.3874\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6595 - accuracy: 0.5945\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.6445 - accuracy: 0.7404\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.6179 - accuracy: 0.7314\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.6025 - accuracy: 0.7215\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5825 - accuracy: 0.7521\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.5408 - accuracy: 0.7324\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.8199\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.8442\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4817 - accuracy: 0.7454\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4093 - accuracy: 0.8128\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3822 - accuracy: 0.8398\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4063 - accuracy: 0.8479\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3519 - accuracy: 0.9041\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3388 - accuracy: 0.8697\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3375 - accuracy: 0.8534\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3009 - accuracy: 0.9007\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3357 - accuracy: 0.8756\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2763 - accuracy: 0.8970\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2387 - accuracy: 0.9135\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2563 - accuracy: 0.9049\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2061 - accuracy: 0.9583\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2395 - accuracy: 0.8970\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2434 - accuracy: 0.8971\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.2044 - accuracy: 1.00 - 0s 1ms/step - loss: 0.2014 - accuracy: 0.9478\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2025 - accuracy: 0.9275\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2646 - accuracy: 0.8919\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1820 - accuracy: 0.9505\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1757 - accuracy: 0.9353\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1940 - accuracy: 0.9312\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1980 - accuracy: 0.9098\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1211 - accuracy: 0.9788\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1086 - accuracy: 0.9790\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1370 - accuracy: 0.9633\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 887us/step - loss: 0.1431 - accuracy: 0.9424\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1499 - accuracy: 0.9265\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0731 - accuracy: 0.9879\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1142 - accuracy: 0.9515\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1232 - accuracy: 0.9533\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.1077 - accuracy: 0.9640\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0419 - accuracy: 1.00 - 0s 2ms/step - loss: 0.0838 - accuracy: 0.9756\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0828 - accuracy: 0.9692\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0767 - accuracy: 0.9951\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0572 - accuracy: 0.9892\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0474 - accuracy: 0.9984\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0457 - accuracy: 0.9987\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0452 - accuracy: 0.9967\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0518 - accuracy: 0.9944\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0746 - accuracy: 0.9750\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0375 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0321 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0240 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0322 - accuracy: 0.9962\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0250 - accuracy: 0.9987\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0248 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0237 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0255 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0166 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0157 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0151 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0145 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0145 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0126 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0155 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0153 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0120 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0092 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0076 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0076 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0022 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22b25d03f48>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(60, input_dim=60, activation='relu'),\n",
    "    keras.layers.Dense(30, activation='relu'),\n",
    "    keras.layers.Dense(15, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 0.9875 - accuracy: 0.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9875056743621826, 0.75]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model has overfitted and so there is high variance in the test accuracy\n",
    "\n",
    "Training Accuracy >>> Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.9610168e-09 9.8247671e-01 9.9292004e-01 1.5000691e-07 9.9998999e-01\n",
      " 9.9917686e-01 5.0317538e-01 9.9999893e-01 6.3819454e-07 9.9999571e-01]\n",
      "[0. 1. 1. 0. 1. 1. 1. 1. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test).reshape(-1)\n",
    "print(y_pred[:10])\n",
    "\n",
    "# round the values to nearest integer ie 0 or 1\n",
    "y_pred = np.round(y_pred)\n",
    "print(y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.85      0.78        27\n",
      "           1       0.80      0.64      0.71        25\n",
      "\n",
      "    accuracy                           0.75        52\n",
      "   macro avg       0.76      0.75      0.75        52\n",
      "weighted avg       0.76      0.75      0.75        52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model with Dropout Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20/20 [==============================] - 1s 4ms/step - loss: 0.7525 - accuracy: 0.4869\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6762 - accuracy: 0.5670\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.7188 - accuracy: 0.5940\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6971 - accuracy: 0.5423\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6990 - accuracy: 0.5012\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5384\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6806 - accuracy: 0.5773\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6964 - accuracy: 0.4569\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6937 - accuracy: 0.4968\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.7075 - accuracy: 0.4932\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6773 - accuracy: 0.5866\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.6956 - accuracy: 0.4963\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 997us/step - loss: 0.6872 - accuracy: 0.5767\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.6865 - accuracy: 0.5068\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6476 - accuracy: 0.6088\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.7171 - accuracy: 0.4828\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.6363 - accuracy: 0.6250\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.7155 - accuracy: 0.4829\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.6744 - accuracy: 0.5840\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6324 - accuracy: 0.6707\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6273 - accuracy: 0.6169\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6591 - accuracy: 0.6318\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.5834 - accuracy: 0.7178\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.6601 - accuracy: 0.6470\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.5851 - accuracy: 0.7030\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.6633 - accuracy: 0.6425\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.5967 - accuracy: 0.7152\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6287 - accuracy: 0.6450\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.5840 - accuracy: 0.6650\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.5260 - accuracy: 0.7726\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5802 - accuracy: 0.7484\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.5326 - accuracy: 0.7461\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.5710 - accuracy: 0.7480\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5943 - accuracy: 0.7906\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.5237 - accuracy: 0.7018\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.5264 - accuracy: 0.7796\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.5481 - accuracy: 0.7140\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.5246 - accuracy: 0.6662\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5271 - accuracy: 0.7741\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.6601 - accuracy: 0.7518\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.5556 - accuracy: 0.7520\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.5745 - accuracy: 0.7984\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.5186 - accuracy: 0.8034\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4681 - accuracy: 0.8191\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4919 - accuracy: 0.7157\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4631 - accuracy: 0.7831\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.5323 - accuracy: 0.6983\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4730 - accuracy: 0.7622\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4541 - accuracy: 0.7662\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4316 - accuracy: 0.8240\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4687 - accuracy: 0.7994\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4696 - accuracy: 0.8113\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4294 - accuracy: 0.8711\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4405 - accuracy: 0.7986\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4643 - accuracy: 0.7674\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4237 - accuracy: 0.8611\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4106 - accuracy: 0.8179\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4300 - accuracy: 0.7690\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.8085\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4235 - accuracy: 0.8487\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 0s 997us/step - loss: 0.4347 - accuracy: 0.8503\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.5364 - accuracy: 0.7779\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4879 - accuracy: 0.8177\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4291 - accuracy: 0.8432\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3901 - accuracy: 0.8367\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4169 - accuracy: 0.7894\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4220 - accuracy: 0.7527\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3949 - accuracy: 0.8386\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4014 - accuracy: 0.8199\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3195 - accuracy: 0.8766\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3844 - accuracy: 0.8227\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3797 - accuracy: 0.8467\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3511 - accuracy: 0.8504\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4501 - accuracy: 0.8156\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4711 - accuracy: 0.7816\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4086 - accuracy: 0.8298\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3758 - accuracy: 0.8144\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3737 - accuracy: 0.8151\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3433 - accuracy: 0.8548\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3269 - accuracy: 0.8286\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3237 - accuracy: 0.8709\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2943 - accuracy: 0.8650\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3055 - accuracy: 0.8802\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3472 - accuracy: 0.8584\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3134 - accuracy: 0.8402\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3338 - accuracy: 0.8276\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3826 - accuracy: 0.8645\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2867 - accuracy: 0.8563\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8525\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3348 - accuracy: 0.8876\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2983 - accuracy: 0.9077\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3446 - accuracy: 0.8312\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3474 - accuracy: 0.9028\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3054 - accuracy: 0.8605\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3501 - accuracy: 0.8312\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3539 - accuracy: 0.8878\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2711 - accuracy: 0.9118\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2338 - accuracy: 0.9507\n",
      "Epoch 99/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2756 - accuracy: 0.8876\n",
      "Epoch 100/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.2577 - accuracy: 0.87 - 0s 1ms/step - loss: 0.2431 - accuracy: 0.8875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22b27f2f608>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeld = keras.Sequential([\n",
    "    keras.layers.Dense(60, input_dim=60, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(30, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(15, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "modeld.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "modeld.fit(X_train, y_train, epochs=100, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4934 - accuracy: 0.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.49343350529670715, 0.75]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeld.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.6525809e-05 9.2176962e-01 9.2364192e-01 1.4500380e-02 9.9890459e-01\n",
      " 9.8017502e-01 2.7638173e-01 9.9887294e-01 1.3807178e-02 9.9965000e-01]\n",
      "[0. 1. 1. 0. 1. 1. 0. 1. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "y_pred = modeld.predict(X_test).reshape(-1)\n",
    "print(y_pred[:10])\n",
    "\n",
    "# round the values to nearest integer ie 0 or 1\n",
    "y_pred = np.round(y_pred)\n",
    "print(y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.89      0.79        27\n",
      "           1       0.83      0.60      0.70        25\n",
      "\n",
      "    accuracy                           0.75        52\n",
      "   macro avg       0.77      0.74      0.74        52\n",
      "weighted avg       0.77      0.75      0.74        52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision and recall have improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
